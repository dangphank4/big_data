---
# Deployment: Spark Streaming Alerts (1-minute abnormal moves)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-streaming-alerts
  namespace: bigdata
  labels:
    app: spark-streaming-alerts
    component: consumer
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-streaming-alerts
  template:
    metadata:
      labels:
        app: spark-streaming-alerts
        component: consumer
    spec:
      containers:
      - name: spark-streaming-alerts
        image: gcr.io/PROJECT_ID/bigdata-spark:latest
        imagePullPolicy: Always
        command:
        - /opt/spark/bin/spark-submit
        - --master
        - local[*]
        - --conf
        - spark.sql.shuffle.partitions=4
        - --conf
        - spark.sql.streaming.minBatchesToRetain=2
        - --conf
        - spark.streaming.stopGracefullyOnShutdown=true
        - --packages
        - org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.3,org.elasticsearch:elasticsearch-spark-30_2.12:7.17.16
        - /app/src/streaming/spark_streaming_alert.py
        env:
        - name: KAFKA_BROKER
          value: "kafka:9092"
        - name: KAFKA_TOPIC
          value: "stocks-realtime-spark"
        - name: ES_NODES
          value: "elasticsearch"
        - name: ES_PORT
          value: "9200"
        - name: ES_ALERT_INDEX
          value: "stock-alerts-1m"
        - name: ALERT_RETURN_PCT_THRESHOLD
          value: "0.01"
        - name: ALERT_RANGE_PCT_THRESHOLD
          value: "0.015"
        - name: CHECKPOINT_LOCATION
          value: "/tmp/spark-alerts-checkpoint"
        volumeMounts:
        - name: checkpoint
          mountPath: /tmp/spark-alerts-checkpoint
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
      volumes:
      - name: checkpoint
        emptyDir: {}
      restartPolicy: Always
