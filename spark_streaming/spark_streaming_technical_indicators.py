"""
SPARK STREAMING JOB: REAL-TIME TECHNICAL INDICATORS FOR STOCK TRADING
===============================================================
M·ª•c ƒë√≠ch: T√≠nh to√°n c√°c ch·ªâ b√°o k·ªπ thu·∫≠t real-time t·ª´ d·ªØ li·ªáu c·ªï phi·∫øu streaming
Ch·ªâ b√°o: RSI, MACD, Moving Averages (SMA, EMA), Bollinger Bands, ATR

G√≥c nh√¨n Trader: C√°c ch·ªâ b√°o n√†y gi√∫p x√°c ƒë·ªãnh:
- ƒêi·ªÉm mua/b√°n (RSI overbought/oversold)
- Xu h∆∞·ªõng th·ªã tr∆∞·ªùng (Moving Averages crossover)
- Bi·∫øn ƒë·ªông v√† r·ªßi ro (Bollinger Bands, ATR)
- Momentum (MACD)
"""

import os
from pyspark.sql import SparkSession
from pyspark.sql.functions import (
    col, from_json, window, avg, stddev, sum, count,
    lag, when, abs, max, min, lit, expr, unix_timestamp,
    to_timestamp, current_timestamp
)
from pyspark.sql.types import (
    StructType, StructField, StringType, DoubleType, 
    TimestampType, LongType
)
from pyspark.sql.window import Window

# ============================================================================
# SCHEMA ƒê·ªäNH NGHƒ®A
# ============================================================================

# Schema cho d·ªØ li·ªáu c·ªï phi·∫øu t·ª´ Kafka
stock_schema = StructType([
    StructField("ticker", StringType(), True),
    StructField("company", StringType(), True),
    StructField("time", StringType(), True),  # S·∫Ω convert sang timestamp
    StructField("Open", DoubleType(), True),
    StructField("High", DoubleType(), True),
    StructField("Low", DoubleType(), True),
    StructField("Close", DoubleType(), True),
    StructField("Volume", DoubleType(), True)
])

# ============================================================================
# H√ÄM T√çNH TO√ÅN CH·ªà B√ÅO K·ª∏ THU·∫¨T
# ============================================================================

def calculate_moving_averages(df, periods=[5, 10, 20, 50]):
    """
    T√≠nh Moving Averages (SMA & EMA)
    
    √ù nghƒ©a Trading:
    - SMA 5/10: Xu h∆∞·ªõng ng·∫Øn h·∫°n (day trading)
    - SMA 20: Xu h∆∞·ªõng trung h·∫°n (swing trading)
    - SMA 50: Xu h∆∞·ªõng d√†i h·∫°n (position trading)
    - Golden Cross: SMA50 c·∫Øt l√™n SMA200 ‚Üí T√≠n hi·ªáu mua m·∫°nh
    - Death Cross: SMA50 c·∫Øt xu·ªëng SMA200 ‚Üí T√≠n hi·ªáu b√°n m·∫°nh
    """
    result_df = df
    
    for period in periods:
        # Window spec cho t·ª´ng ticker
        windowSpec = Window.partitionBy("ticker").orderBy("timestamp").rowsBetween(-(period-1), 0)
        
        # Simple Moving Average
        result_df = result_df.withColumn(
            f"SMA_{period}",
            avg("Close").over(windowSpec)
        )
        
        # Exponential Moving Average (EMA)
        # EMA = Close * multiplier + EMA(previous) * (1 - multiplier)
        # multiplier = 2 / (period + 1)
        multiplier = 2.0 / (period + 1)
        
        # T√≠nh EMA ƒë∆°n gi·∫£n (c√≥ th·ªÉ t·ªëi ∆∞u h∆°n v·ªõi state store)
        result_df = result_df.withColumn(
            f"EMA_{period}",
            avg("Close").over(windowSpec)  # Simplified version
        )
    
    return result_df

def calculate_rsi(df, period=14):
    """
    T√≠nh RSI (Relative Strength Index)
    
    √ù nghƒ©a Trading:
    - RSI > 70: Overbought (qu√° mua) ‚Üí C√¢n nh·∫Øc b√°n
    - RSI < 30: Oversold (qu√° b√°n) ‚Üí C√¢n nh·∫Øc mua
    - RSI 50: V√πng trung l·∫≠p
    - Divergence: Gi√° t·∫°o ƒë·ªânh m·ªõi nh∆∞ng RSI kh√¥ng ‚Üí T√≠n hi·ªáu ƒë·∫£o chi·ªÅu
    
    C√¥ng th·ª©c:
    RSI = 100 - (100 / (1 + RS))
    RS = Average Gain / Average Loss
    """
    windowSpec = Window.partitionBy("ticker").orderBy("timestamp")
    
    # T√≠nh price change
    df_with_change = df.withColumn(
        "price_change",
        col("Close") - lag("Close", 1).over(windowSpec)
    )
    
    # T√°ch gain v√† loss
    df_with_change = df_with_change.withColumn(
        "gain",
        when(col("price_change") > 0, col("price_change")).otherwise(0)
    ).withColumn(
        "loss",
        when(col("price_change") < 0, abs(col("price_change"))).otherwise(0)
    )
    
    # T√≠nh average gain v√† loss trong period
    windowSpec_period = Window.partitionBy("ticker").orderBy("timestamp").rowsBetween(-(period-1), 0)
    
    df_with_rs = df_with_change.withColumn(
        "avg_gain",
        avg("gain").over(windowSpec_period)
    ).withColumn(
        "avg_loss",
        avg("loss").over(windowSpec_period)
    )
    
    # T√≠nh RSI
    df_with_rsi = df_with_rs.withColumn(
        "RS",
        when(col("avg_loss") != 0, col("avg_gain") / col("avg_loss")).otherwise(100)
    ).withColumn(
        "RSI",
        100 - (100 / (1 + col("RS")))
    ).withColumn(
        "RSI_signal",
        when(col("RSI") > 70, "OVERBOUGHT")
        .when(col("RSI") < 30, "OVERSOLD")
        .otherwise("NEUTRAL")
    )
    
    return df_with_rsi

def calculate_macd(df, fast=12, slow=26, signal=9):
    """
    T√≠nh MACD (Moving Average Convergence Divergence)
    
    √ù nghƒ©a Trading:
    - MACD Line c·∫Øt l√™n Signal Line ‚Üí T√≠n hi·ªáu mua (Bullish)
    - MACD Line c·∫Øt xu·ªëng Signal Line ‚Üí T√≠n hi·ªáu b√°n (Bearish)
    - Histogram > 0: Xu h∆∞·ªõng tƒÉng m·∫°nh l√™n
    - Histogram < 0: Xu h∆∞·ªõng gi·∫£m m·∫°nh l√™n
    
    C√¥ng th·ª©c:
    MACD Line = EMA(12) - EMA(26)
    Signal Line = EMA(9) of MACD Line
    Histogram = MACD Line - Signal Line
    """
    windowSpec = Window.partitionBy("ticker").orderBy("timestamp")
    
    # T√≠nh EMA fast v√† slow
    window_fast = windowSpec.rowsBetween(-(fast-1), 0)
    window_slow = windowSpec.rowsBetween(-(slow-1), 0)
    
    df_with_ema = df.withColumn(
        "EMA_fast",
        avg("Close").over(window_fast)
    ).withColumn(
        "EMA_slow",
        avg("Close").over(window_slow)
    )
    
    # MACD Line
    df_with_macd = df_with_ema.withColumn(
        "MACD_line",
        col("EMA_fast") - col("EMA_slow")
    )
    
    # Signal Line (EMA of MACD)
    window_signal = windowSpec.rowsBetween(-(signal-1), 0)
    df_with_signal = df_with_macd.withColumn(
        "MACD_signal",
        avg("MACD_line").over(window_signal)
    )
    
    # Histogram v√† Trading Signal
    df_final = df_with_signal.withColumn(
        "MACD_histogram",
        col("MACD_line") - col("MACD_signal")
    ).withColumn(
        "MACD_crossover",
        when(
            (col("MACD_line") > col("MACD_signal")) & 
            (lag("MACD_line", 1).over(windowSpec) <= lag("MACD_signal", 1).over(windowSpec)),
            "BULLISH_CROSSOVER"
        ).when(
            (col("MACD_line") < col("MACD_signal")) & 
            (lag("MACD_line", 1).over(windowSpec) >= lag("MACD_signal", 1).over(windowSpec)),
            "BEARISH_CROSSOVER"
        ).otherwise("NO_SIGNAL")
    )
    
    return df_final

def calculate_bollinger_bands(df, period=20, std_dev=2):
    """
    T√≠nh Bollinger Bands
    
    √ù nghƒ©a Trading:
    - Gi√° ch·∫°m Upper Band: Overbought ‚Üí C√¢n nh·∫Øc b√°n
    - Gi√° ch·∫°m Lower Band: Oversold ‚Üí C√¢n nh·∫Øc mua
    - Bandwidth h·∫πp: Consolidation (t√≠ch l≈©y) ‚Üí S·∫Øp breakout
    - Bandwidth r·ªông: Volatility cao ‚Üí Xu h∆∞·ªõng m·∫°nh
    - Price breaks Upper Band: Strong bullish ‚Üí Ti·∫øp t·ª•c uptrend
    - Price breaks Lower Band: Strong bearish ‚Üí Ti·∫øp t·ª•c downtrend
    """
    windowSpec = Window.partitionBy("ticker").orderBy("timestamp").rowsBetween(-(period-1), 0)
    
    df_with_bands = df.withColumn(
        "BB_middle",
        avg("Close").over(windowSpec)
    ).withColumn(
        "BB_std",
        stddev("Close").over(windowSpec)
    ).withColumn(
        "BB_upper",
        col("BB_middle") + (col("BB_std") * std_dev)
    ).withColumn(
        "BB_lower",
        col("BB_middle") - (col("BB_std") * std_dev)
    ).withColumn(
        "BB_width",
        col("BB_upper") - col("BB_lower")
    ).withColumn(
        "BB_position",
        (col("Close") - col("BB_lower")) / (col("BB_upper") - col("BB_lower"))
    ).withColumn(
        "BB_signal",
        when(col("Close") >= col("BB_upper"), "UPPER_TOUCH")
        .when(col("Close") <= col("BB_lower"), "LOWER_TOUCH")
        .when(col("BB_position") > 0.8, "NEAR_UPPER")
        .when(col("BB_position") < 0.2, "NEAR_LOWER")
        .otherwise("MIDDLE_RANGE")
    )
    
    return df_with_bands

def calculate_atr(df, period=14):
    """
    T√≠nh ATR (Average True Range)
    
    √ù nghƒ©a Trading:
    - ƒêo l∆∞·ªùng volatility (bi·∫øn ƒë·ªông)
    - ATR cao: Th·ªã tr∆∞·ªùng bi·∫øn ƒë·ªông m·∫°nh ‚Üí R·ªßi ro cao, d·ª´ng l·ªó r·ªông h∆°n
    - ATR th·∫•p: Th·ªã tr∆∞·ªùng √≠t bi·∫øn ƒë·ªông ‚Üí R·ªßi ro th·∫•p, d·ª´ng l·ªó h·∫πp h∆°n
    - S·ª≠ d·ª•ng cho Stop Loss: Stop Loss = Entry Price ¬± (ATR √ó multiplier)
    """
    windowSpec = Window.partitionBy("ticker").orderBy("timestamp")
    
    # T√≠nh True Range
    df_with_prev = df.withColumn(
        "prev_close",
        lag("Close", 1).over(windowSpec)
    )
    
    df_with_tr = df_with_prev.withColumn(
        "TR",
        expr("""
            GREATEST(
                High - Low,
                ABS(High - prev_close),
                ABS(Low - prev_close)
            )
        """)
    )
    
    # Average True Range
    window_period = windowSpec.rowsBetween(-(period-1), 0)
    df_with_atr = df_with_tr.withColumn(
        "ATR",
        avg("TR").over(window_period)
    ).withColumn(
        "ATR_percent",
        (col("ATR") / col("Close")) * 100
    ).withColumn(
        "volatility_level",
        when(col("ATR_percent") > 3, "HIGH_VOLATILITY")
        .when(col("ATR_percent") > 1.5, "MODERATE_VOLATILITY")
        .otherwise("LOW_VOLATILITY")
    )
    
    return df_with_atr

def generate_trading_signals(df):
    """
    T·ªïng h·ª£p c√°c t√≠n hi·ªáu trading t·ª´ nhi·ªÅu ch·ªâ b√°o
    
    Chi·∫øn l∆∞·ª£c Multi-Indicator Confirmation:
    - STRONG BUY: RSI < 30 + MACD Bullish + Price near BB Lower
    - BUY: 2/3 indicators bullish
    - STRONG SELL: RSI > 70 + MACD Bearish + Price near BB Upper
    - SELL: 2/3 indicators bearish
    - HOLD: Mixed signals
    """
    df_with_signals = df.withColumn(
        "bullish_count",
        (when(col("RSI") < 30, 1).otherwise(0) +
         when(col("MACD_crossover") == "BULLISH_CROSSOVER", 1).otherwise(0) +
         when(col("BB_signal").isin(["LOWER_TOUCH", "NEAR_LOWER"]), 1).otherwise(0))
    ).withColumn(
        "bearish_count",
        (when(col("RSI") > 70, 1).otherwise(0) +
         when(col("MACD_crossover") == "BEARISH_CROSSOVER", 1).otherwise(0) +
         when(col("BB_signal").isin(["UPPER_TOUCH", "NEAR_UPPER"]), 1).otherwise(0))
    ).withColumn(
        "overall_signal",
        when(col("bullish_count") >= 3, "STRONG_BUY")
        .when(col("bullish_count") == 2, "BUY")
        .when(col("bearish_count") >= 3, "STRONG_SELL")
        .when(col("bearish_count") == 2, "SELL")
        .otherwise("HOLD")
    ).withColumn(
        "signal_strength",
        when(col("overall_signal").isin(["STRONG_BUY", "STRONG_SELL"]), 
             (col("bullish_count") + col("bearish_count")) / 3.0)
        .otherwise(0.5)
    )
    
    return df_with_signals

# ============================================================================
# MAIN STREAMING JOB
# ============================================================================

if __name__ == "__main__":
    print("=" * 80)
    print("üöÄ B·∫ÆT ƒê·∫¶U SPARK STREAMING: TECHNICAL INDICATORS REAL-TIME")
    print("=" * 80)
    
    # L·∫•y config t·ª´ environment variables
    KAFKA_BROKER = os.getenv("KAFKA_BROKER", "kafka:9092")
    KAFKA_TOPIC = os.getenv("KAFKA_TOPIC", "stock-realtime-topic")
    ES_NODES = os.getenv("ES_NODES", "elasticsearch")
    ES_PORT = os.getenv("ES_PORT", "9200")
    ES_INDEX = os.getenv("ES_INDEX", "stock_technical_indicators")
    CHECKPOINT_LOCATION = os.getenv(
        "CHECKPOINT_LOCATION",
        "hdfs://hadoop-namenode:8020/user/spark_checkpoints/stock_technical_indicators"
    )
    
    # Kh·ªüi t·∫°o Spark Session
    print("\nüìä Kh·ªüi t·∫°o SparkSession...")
    spark = SparkSession.builder \
        .appName("Stock Technical Indicators Real-time") \
        .config("spark.es.nodes", ES_NODES) \
        .config("spark.es.port", ES_PORT) \
        .config("spark.es.nodes.wan.only", "true") \
        .config("spark.sql.streaming.checkpointLocation", CHECKPOINT_LOCATION) \
        .config("spark.sql.shuffle.partitions", "4") \
        .getOrCreate()
    
    spark.sparkContext.setLogLevel("WARN")
    print("‚úÖ SparkSession ƒë√£ s·∫µn s√†ng")
    
    # ƒê·ªçc streaming data t·ª´ Kafka
    print(f"\nüì° ƒê·ªçc d·ªØ li·ªáu t·ª´ Kafka - Broker: {KAFKA_BROKER}, Topic: {KAFKA_TOPIC}")
    kafka_df = spark.readStream \
        .format("kafka") \
        .option("kafka.bootstrap.servers", KAFKA_BROKER) \
        .option("subscribe", KAFKA_TOPIC) \
        .option("startingOffsets", "earliest") \
        .option("failOnDataLoss", "false") \
        .load()
    
    # Parse JSON data
    print("\nüîç Parse d·ªØ li·ªáu JSON t·ª´ Kafka...")
    parsed_df = kafka_df \
        .select(
            col("value").cast(StringType())
        ) \
        .filter(col("value").isNotNull()) \
        .withColumn("data", from_json(col("value"), stock_schema)) \
        .select("data.*") \
        .withColumn("timestamp", to_timestamp(col("time"))) \
        .filter(col("Close").isNotNull())
    
    # Th√™m watermark ƒë·ªÉ x·ª≠ l√Ω late data
    print("\n‚è∞ √Åp d·ª•ng Watermark (10 ph√∫t)...")
    watermarked_df = parsed_df.withWatermark("timestamp", "10 minutes")
    
    # T√≠nh c√°c ch·ªâ b√°o k·ªπ thu·∫≠t
    print("\nüìà T√≠nh to√°n c√°c ch·ªâ b√°o k·ªπ thu·∫≠t...")
    print("  - Moving Averages (SMA 5, 10, 20, 50)")
    df_with_ma = calculate_moving_averages(watermarked_df, periods=[5, 10, 20, 50])
    
    print("  - RSI (Relative Strength Index)")
    df_with_rsi = calculate_rsi(df_with_ma, period=14)
    
    print("  - MACD (Moving Average Convergence Divergence)")
    df_with_macd = calculate_macd(df_with_rsi, fast=12, slow=26, signal=9)
    
    print("  - Bollinger Bands")
    df_with_bb = calculate_bollinger_bands(df_with_macd, period=20, std_dev=2)
    
    print("  - ATR (Average True Range)")
    df_with_atr = calculate_atr(df_with_bb, period=14)
    
    print("  - T·ªïng h·ª£p Trading Signals")
    df_final = generate_trading_signals(df_with_atr)
    
    # Ch·ªçn c√°c c·ªôt quan tr·ªçng ƒë·ªÉ l∆∞u
    output_df = df_final.select(
        "timestamp",
        "ticker",
        "company",
        "Open", "High", "Low", "Close", "Volume",
        # Moving Averages
        "SMA_5", "SMA_10", "SMA_20", "SMA_50",
        # RSI
        "RSI", "RSI_signal",
        # MACD
        "MACD_line", "MACD_signal", "MACD_histogram", "MACD_crossover",
        # Bollinger Bands
        "BB_upper", "BB_middle", "BB_lower", "BB_width", "BB_position", "BB_signal",
        # ATR
        "ATR", "ATR_percent", "volatility_level",
        # Trading Signals
        "bullish_count", "bearish_count", "overall_signal", "signal_strength"
    )
    
    # Ghi k·∫øt qu·∫£ v√†o Elasticsearch using foreachBatch (compatible with ES 7.17 + Spark 3.5)
    print(f"\nüíæ Ghi k·∫øt qu·∫£ v√†o Elasticsearch - Index: {ES_INDEX}")
    
    def write_to_es(batch_df, batch_id):
        if batch_df.count() > 0:
            print(f"\nüì¶ Processing batch {batch_id} with {batch_df.count()} records")
            batch_df.write \
                .format("org.elasticsearch.spark.sql") \
                .option("es.resource", ES_INDEX) \
                .option("es.nodes", ES_NODES) \
                .option("es.port", ES_PORT) \
                .option("es.nodes.wan.only", "true") \
                .option("es.batch.size.entries", "100") \
                .option("es.write.operation", "index") \
                .mode("append") \
                .save()
            print(f"‚úÖ Batch {batch_id} written to Elasticsearch")
    
    query = output_df.writeStream \
        .outputMode("append") \
        .foreachBatch(write_to_es) \
        .option("checkpointLocation", CHECKPOINT_LOCATION) \
        .start()
    
    # Console output for monitoring (optional)
    console_query = output_df \
        .filter(col("overall_signal").isin(["STRONG_BUY", "STRONG_SELL", "BUY", "SELL"])) \
        .writeStream \
        .outputMode("append") \
        .format("console") \
        .option("truncate", "false") \
        .start()
    
    print("\n" + "=" * 80)
    print("‚úÖ STREAMING JOB ƒêANG CH·∫†Y (ForeachBatch mode) - Monitoring trading signals...")
    print("=" * 80)
    print("\nüìä C√°c t√≠n hi·ªáu STRONG_BUY/STRONG_SELL s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã ·ªü console\n")
    
    # Ch·ªù streaming job
    query.awaitTermination()
    console_query.awaitTermination()
