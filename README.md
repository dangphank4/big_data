# Big Data Real-Time Stock Analysis Pipeline

## ğŸ“Š Tá»•ng Quan

Pipeline phÃ¢n tÃ­ch cá»• phiáº¿u real-time sá»­ dá»¥ng:

- **Kafka** - Message streaming
- **Spark Streaming** - Xá»­ lÃ½ real-time
- **Elasticsearch** - LÆ°u trá»¯ dá»¯ liá»‡u
- **Kibana** - Visualization
- **HDFS** - Checkpoint storage

## ğŸš€ Quick Start

### 1. Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng

```bash
docker compose up -d
sleep 30

# Start Producer
docker exec python-worker bash -c "cd /app && nohup python kafka_producer.py > /tmp/producer.log 2>&1 &"

# Äá»£i 2 phÃºt vÃ  kiá»ƒm tra
sleep 120
curl -s "http://localhost:9200/_cat/indices?v" | grep stock
```

### 2. Má»Ÿ Kibana

```
http://localhost:5601
```

Táº¡o Index Pattern: `stock_realtime` vá»›i time field `window_start`

## ğŸ“– TÃ i Liá»‡u Chi Tiáº¿t

Xem file: **[HUONG_DAN_SU_DUNG.md](HUONG_DAN_SU_DUNG.md)**

## ğŸ›‘ Dá»«ng & Reset

```bash
docker compose down
docker volume rm big_data_es_data big_data_kafka_data 2>/dev/null || true
```

## ğŸ“ Cáº¥u TrÃºc

```
â”œâ”€â”€ docker-compose.yml              # Äá»‹nh nghÄ©a services
â”œâ”€â”€ kafka_producer.py               # Producer gá»­i dá»¯ liá»‡u
â”œâ”€â”€ spark_streaming/
â”‚   â”œâ”€â”€ spark_streaming_simple.py              # Job chÃ­nh
â”‚   â”œâ”€â”€ spark_streaming_technical_indicators.py # Technical analysis
â”‚   â””â”€â”€ spark_streaming_anomaly_detection.py   # Anomaly detection
â””â”€â”€ HUONG_DAN_SU_DUNG.md           # HÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§
```

## âœ… Kiá»ƒm Tra Há»‡ Thá»‘ng

```bash
# Services
docker compose ps

# Producer logs
docker exec python-worker tail -10 /tmp/producer.log

# Spark logs
docker logs spark-streaming-simple --tail 20

# Elasticsearch
curl "http://localhost:9200/_cat/indices?v" | grep stock
```
